{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED MODULES\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import gsw\n",
    "import gsw.density as gsw_density\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMG ALAMO Floats (F9250 & F9313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JSON files in ALAMO_F9250 directory: 90\n",
      "Number of JSON files in ALAMO_F9313 directory: 94\n"
     ]
    }
   ],
   "source": [
    "# The ALAMO F9250 & F9313 datasets are provided as JSON files. To begin, the number of JSON in each directory is printed.\n",
    "\n",
    "# Calculate the number of JSON files within a specified directory\n",
    "def count_json_files(directory):\n",
    "    file_count = 0\n",
    "    for (dir_path, _, file_names) in os.walk(os.path.normpath(directory)):\n",
    "        for file in file_names:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_count += 1\n",
    "    return file_count\n",
    "\n",
    "ALAMO_F9250_directory = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9250/'\n",
    "ALAMO_F9313_directory = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9313/'\n",
    "print(f\"Number of JSON files in ALAMO_F9250 directory: {count_json_files(ALAMO_F9250_directory)}\")\n",
    "print(f\"Number of JSON files in ALAMO_F9313 directory: {count_json_files(ALAMO_F9313_directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following block, specify the directory to be used (ALAMO_F9250 or ALAMO F9313), and the desired output filename. \n",
    "# The potential density range from which data is selected is based upon the boundary conditions outlined by Gladish et al. (2015a) \n",
    "directory = ALAMO_F9250_directory\n",
    "output_filename = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9250/f9250_pd_27.10_27.31.csv'\n",
    "column_order = ['date', 'lon', 'lat', 'temperature', 'salinity', 'pressure', 'depth', 'potential_density', 'sigma_theta']\n",
    "desired_sigma_theta_min = 27.20\n",
    "desired_sigma_theta_max = 27.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with potential density in the desired range saved to R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9313/f9313_pd_27.10_27.31.csv\n"
     ]
    }
   ],
   "source": [
    "# The following code  extracts all data within the desired potential density range, outputting the results to a csv. Note that both depth is calculated from pressure, and\n",
    "# potential density is calculated using salinity and temperature, using the gsw package from the Gibbs-SeaWater (GSW) Oceanographic Toolbox (https://www.teos-10.org/software.htm#1). \n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data.\n",
    "dfs = []\n",
    "\n",
    "# Within the specified directory, open each JSON file in read mode. \n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_path = os.path.join(directory, filename)\n",
    "        with open(json_path, 'r') as openfile:\n",
    "            CTD_data = json.load(openfile)\n",
    "        CTD_data_dict = CTD_data[0]\n",
    "\n",
    "        # Extract the longitude and latitude from the 'DiveStart'. If the JSON file doesn't have any lon or lat values, the file is skipped. \n",
    "        lat = CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lat', None)\n",
    "        lon = CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lon', None)\n",
    "        if lat == 0 or lon == 0:\n",
    "            continue\n",
    "\n",
    "        # Define the temperature, salinity and pressure keys within the CTD data dictionary.\n",
    "        temperature = CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('temperature', [])\n",
    "        salinity = CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('salinity', [])\n",
    "        pressure = np.array(CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('pressure', []))\n",
    "\n",
    "        # Check that the temperature and pressure variables are the same length (i.e. no missing values)\n",
    "        if len(temperature) == len(pressure) > 0:\n",
    "\n",
    "            # Using the gsw package, calculate (i) depth from pressure, and (ii) potential density from salinity and temperature.\n",
    "            latitude = 69.2\n",
    "            depth = -1 * gsw.z_from_p(pressure, latitude)\n",
    "            potential_density = gsw.density.rho(salinity, temperature, pressure)\n",
    "            sigma_theta = potential_density - 1000\n",
    "\n",
    "            # Create a dictionary with the keys for each desired variable. Convert this dictionary to a pandas DataFrame.\n",
    "            data_dict = {'temperature': temperature, 'salinity': salinity, 'pressure': pressure, 'depth': depth, 'potential_density': potential_density, 'sigma_theta': sigma_theta,\n",
    "                         'lon': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lon', None)] * len(temperature),\n",
    "                         'lat': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lat', None)] * len(temperature),\n",
    "                         'date': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('datetime', None)] * len(temperature)}\n",
    "            df = pd.DataFrame(data_dict)\n",
    "\n",
    "            # Filter rows based on the desired range of potential density.\n",
    "            filtered_df = df[(df['sigma_theta'] >= desired_sigma_theta_min) & (df['sigma_theta'] <= desired_sigma_theta_max)]\n",
    "\n",
    "            # Append the filtered data to the combined DataFrame\n",
    "            dfs.append(filtered_df)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df = pd.concat(dfs, ignore_index=True)            \n",
    "combined_df.to_csv(output_filename, index=False, columns=column_order)\n",
    "print(f'Data with potential density in the desired range saved to {output_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greenland Ecosystem Monitoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The GEM Database was searched using ‘MarineBasis Disko’ - ‘Water Column’ - ‘CTD Measurments’ - ‘2018-01-01 to 2022-12-31’. This csv was downloaded, named as \n",
    " # 'ctd_download_disko_bay.csv'. The following block of code extracts all data within the specified potential density range, outputting the results to a csv. \n",
    "\n",
    "# Open the GEM CTD data provided for Disko Bay between 2018 and 2023. \n",
    "gem_data = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/ctd_download_disko_bay.csv'\n",
    "df = pd.read_csv(gem_data, encoding='ISO-8859-1')\n",
    "\n",
    "# Filter the GEM CTD data within the specified potential density range.\n",
    "desired_pd_min = 1027.20\n",
    "desired_pd_max = 1027.31\n",
    "filtered_df = df[(df['Density (kg/m^3)'] >= desired_pd_min) & (df['Density (kg/m^3)'] <= desired_pd_max)]\n",
    "\n",
    "# Export each profile, defined by date, to a CSV.\n",
    "grouped = filtered_df.groupby('Date')\n",
    "output_folder = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/individual_profiles/'\n",
    "for date, group in grouped:\n",
    "    formatted_date = date.replace('/', '-')\n",
    "    output_folder_date = os.path.join(output_folder, f'GEM_CSV_profile_{formatted_date}')\n",
    "    output_filename = os.path.join(output_folder, f'GEM_CSV_profile_{formatted_date}.csv')\n",
    "    group.to_csv(output_filename, index=False)\n",
    "\n",
    "# Output and save a combined csv of all profiles filtered between the desired potential density threshold. \n",
    "csv_files = [file for file in os.listdir(output_folder) if file.endswith('.csv')]\n",
    "combined_df = pd.DataFrame()\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(output_folder, csv_file)\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1')  \n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "output_file = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/ctd_filtered_disko_bay.csv'\n",
    "combined_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMG APEX F9184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV files have beeen filtered and saved.\n"
     ]
    }
   ],
   "source": [
    "# The OMG APEX F9184 data are provided as 'science logs', which include the scientific data for each dive, including the temperature, salinity and pressure profiles, \n",
    "# and GPS locations. To begin, these science logs are filtered in order to remove those without pressure, temperature and salinity data. \n",
    "\n",
    "# Define the directory containing the science logs. \n",
    "input_directory = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_apex_f9184/science_logs/'\n",
    "\n",
    "# Define the directory to which the filtered science logs should be saved. \n",
    "output_folder = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_apex_f9184/filtered_science_logs/'\n",
    "\n",
    "# Define the rows to export based on the 'message' column (export those with at least pressure, temperature and salinity) \n",
    "target_strings = ['LGR_CP_PTS', 'LGR_CP_PTSC', 'LGR_CP_PTSCI']\n",
    "\n",
    "# COLUMNS TO LABEL IN EACH OUTPUT CSV\n",
    "desired_columns = ['MESSAGE', 'TIME', 'PRESSURE', 'TEMP', 'SALINITY', 'CONDUCTIVITY', 'INTERNAL_TEMP']\n",
    "\n",
    "# Loop through each csv within the input directory \n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        output_filename = f'filtered_{filename}'\n",
    "        output_filepath = os.path.join(output_folder, output_filename)\n",
    "        with open(input_filepath, 'r') as infile, open(output_filepath, 'w', newline='') as outfile:\n",
    "            reader = csv.reader(infile)\n",
    "            writer = csv.writer(outfile)\n",
    "            # Write the new column names\n",
    "            writer.writerow(desired_columns)\n",
    "            # Iterate through rows and write only if the first column matches the target strings\n",
    "            for row in reader:\n",
    "                if row and row[0] in target_strings:\n",
    "                    # Extract the values in the desired order\n",
    "                    filtered_row = [row[0], row[1], row[2], row[3], row[4], row[5], row[6]]\n",
    "                    writer.writerow(filtered_row)\n",
    "\n",
    "print(\"The CSV files have been filtered and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the filtered science logs, potential density is then calculated using the gsw package. The code then extracts all data within the specified potential density \n",
    "# range, outputting the results to a csv named 'f9184_pd_27.10_27.31'.\n",
    "\n",
    "filtered_logs_directory = ('R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_apex_f9184/filtered_science_logs/')\n",
    "output_directory = ('R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_apex_f9184/')\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(filtered_logs_directory)\n",
    "\n",
    "# Create an empty DataFrame to store the combined filtered data\n",
    "combined_filtered_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each csv file in the directory, constructing the file path and reading the csv. \n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(filtered_logs_directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculate potential density and add as a new column\n",
    "        salinity = df['SALINITY']  \n",
    "        temperature = df['TEMP']\n",
    "        pressure = df['PRESSURE']\n",
    "        potential_density = gsw.density.rho(salinity, temperature, pressure)\n",
    "        df['potential_density'] = potential_density\n",
    "\n",
    "        # Filter each dataframe within the specified potential density range \n",
    "        filtered_df = df[(df['potential_density'] >= 1027.20) & (df['potential_density'] <= 1027.31)]\n",
    "\n",
    "        # Combine the filtered data into a single dataframe.\n",
    "        combined_filtered_df = pd.concat([combined_filtered_df, filtered_df], ignore_index=True)\n",
    "\n",
    "combined_output_file = os.path.join(output_directory, 'f9184_pd_27.10_27.31.csv')\n",
    "combined_filtered_df.to_csv(combined_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velocity_download",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
