{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED MODULES\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import gsw\n",
    "import gsw.density as gsw_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMG ALAMO Floats (F9250 & F9313)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ALAMO F9250 & F9313 datasets are provided as JSON files. To begin, the number of JSON files in each directory is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JSON files in ALAMO_F9250 directory: 90\n",
      "Number of JSON files in ALAMO_F9313 directory: 94\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of JSON files within a specified directory\n",
    "def count_json_files(directory):\n",
    "    file_count = 0\n",
    "    for (dir_path, _, file_names) in os.walk(os.path.normpath(directory)):\n",
    "        for file in file_names:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_count += 1\n",
    "    return file_count\n",
    "\n",
    "ALAMO_F9250_directory = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9250/'\n",
    "ALAMO_F9313_directory = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9313/'\n",
    "print(f\"Number of JSON files in ALAMO_F9250 directory: {count_json_files(ALAMO_F9250_directory)}\")\n",
    "print(f\"Number of JSON files in ALAMO_F9313 directory: {count_json_files(ALAMO_F9313_directory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block, specify the directory to be used (i.e. either ALAMO_F9250_directory or ALAMO_F9313_directory), and the desired csv output filename.\n",
    "\n",
    "The potential density range from which data is selected is based upon the potential density values provided by Gladish et al. (2015a) - i.e. between 27.20 and 27.31 kg/m3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory, desired potential density (sigma_theta) range, and output filename. \n",
    "directory = ALAMO_F9250_directory\n",
    "output_filename = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9250/f9250_pd_27.10_27.31.csv'\n",
    "column_order = ['date', 'lon', 'lat', 'temperature', 'salinity', 'pressure', 'depth', 'potential_density', 'sigma_theta']\n",
    "desired_sigma_theta_min = 27.20\n",
    "desired_sigma_theta_max = 27.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block extracts all data within the desired potential density range, outputting the results to a csv. \n",
    "\n",
    "Note that both depth is calculated from pressure, and potential density is calculated using salinity and temperature, using the gsw package from the Gibbs-SeaWater (GSW) Oceanographic Toolbox (https://www.teos-10.org/software.htm#1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with potential density in the desired range saved to R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/omg_alamo_f9313/f9313_pd_27.10_27.31.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the combined data.\n",
    "dfs = []\n",
    "\n",
    "# Within the specified directory, open each JSON file in read mode. \n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_path = os.path.join(directory, filename)\n",
    "        with open(json_path, 'r') as openfile:\n",
    "            CTD_data = json.load(openfile)\n",
    "        CTD_data_dict = CTD_data[0]\n",
    "\n",
    "        # Extract the longitude and latitude from the 'DiveStart'. If the JSON file doesn't have any lon or lat values, the file is skipped. \n",
    "        lat = CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lat', None)\n",
    "        lon = CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lon', None)\n",
    "        if lat == 0 or lon == 0:\n",
    "            continue\n",
    "\n",
    "        # Define the temperature, salinity and pressure keys within the CTD data dictionary.\n",
    "        temperature = CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('temperature', [])\n",
    "        salinity = CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('salinity', [])\n",
    "        pressure = np.array(CTD_data_dict.get('dives', [])[0].get('science', {}).get('ascending', {}).get('binned', {}).get('pressure', []))\n",
    "\n",
    "        # Check that the temperature and pressure variables are the same length (i.e. no missing values)\n",
    "        if len(temperature) == len(pressure) > 0:\n",
    "\n",
    "            # Using the gsw package, calculate (i) depth from pressure, and (ii) potential density from salinity and temperature.\n",
    "            latitude = 69.2\n",
    "            depth = -1 * gsw.z_from_p(pressure, latitude)\n",
    "            potential_density = gsw.density.rho(salinity, temperature, pressure)\n",
    "            sigma_theta = potential_density - 1000\n",
    "\n",
    "            # Create a dictionary with the keys for each desired variable. Convert this dictionary to a pandas DataFrame.\n",
    "            data_dict = {'temperature': temperature, 'salinity': salinity, 'pressure': pressure, 'depth': depth, 'potential_density': potential_density, 'sigma_theta': sigma_theta,\n",
    "                         'lon': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lon', None)] * len(temperature),\n",
    "                         'lat': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('lat', None)] * len(temperature),\n",
    "                         'date': [CTD_data_dict.get('dives', [])[0].get('trajectory', {}).get('gps', [])[0].get('datetime', None)] * len(temperature)}\n",
    "            df = pd.DataFrame(data_dict)\n",
    "\n",
    "            # Filter rows based on the desired range of potential density.\n",
    "            filtered_df = df[(df['sigma_theta'] >= desired_sigma_theta_min) & (df['sigma_theta'] <= desired_sigma_theta_max)]\n",
    "\n",
    "            # Append the filtered data to the combined DataFrame\n",
    "            dfs.append(filtered_df)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df = pd.concat(dfs, ignore_index=True)            \n",
    "combined_df.to_csv(output_filename, index=False, columns=column_order)\n",
    "print(f'Data with potential density in the desired range saved to {output_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greenland Ecosystem Monitoring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GEM Database was searched using ‘MarineBasis Disko’ - ‘Water Column’ - ‘CTD Measurments’ - ‘2018-01-01 to 2022-12-31’. This csv was downloaded, being named as 'ctd_download_disko_bay.csv'. \n",
    "\n",
    "The following block of code extracts all data within the specified potential density range, outputting the results to a csv named 'ctd_filtered_disko_bay'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the GEM CTD data provided for Disko Bay between 2018 and 2023. \n",
    "gem_data = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/ctd_download_disko_bay.csv'\n",
    "df = pd.read_csv(gem_data, encoding='ISO-8859-1')\n",
    "\n",
    "# Filter the GEM CTD data within the specified potential density range.\n",
    "desired_pd_min = 1027.20\n",
    "desired_pd_max = 1027.31\n",
    "filtered_df = df[(df['Density (kg/m^3)'] >= desired_pd_min) & (df['Density (kg/m^3)'] <= desired_pd_max)]\n",
    "\n",
    "# Export each profile, defined by date, to a CSV.\n",
    "grouped = filtered_df.groupby('Date')\n",
    "output_folder = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/individual_profiles/'\n",
    "for date, group in grouped:\n",
    "    formatted_date = date.replace('/', '-')\n",
    "    output_folder_date = os.path.join(output_folder, f'GEM_CSV_profile_{formatted_date}')\n",
    "    output_filename = os.path.join(output_folder, f'GEM_CSV_profile_{formatted_date}.csv')\n",
    "    group.to_csv(output_filename, index=False)\n",
    "\n",
    "# Output and save a combined csv of all profiles filtered between the desired potential density threshold. \n",
    "csv_files = [file for file in os.listdir(output_folder) if file.endswith('.csv')]\n",
    "combined_df = pd.DataFrame()\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(output_folder, csv_file)\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1')  \n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "output_file = 'R:/JAKOBSHAVN/CODE/github/jakobshavn_isbrae/data/gem_ctd_disko_bay/ctd_filtered_disko_bay.csv'\n",
    "combined_df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velocity_download",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
